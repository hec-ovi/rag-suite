services:
  qdrant:
    image: qdrant/qdrant:v1.17.0
    container_name: rag-suite-qdrant
    restart: unless-stopped
    volumes:
      - ${QDRANT_STORAGE_DIR}:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"
    healthcheck:
      test: ["CMD-SHELL", "bash -lc 'exec 3<>/dev/tcp/127.0.0.1/6333'"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 15s

  ollama:
    image: ollama/ollama:rocm
    container_name: rag-suite-ollama
    restart: unless-stopped
    privileged: true
    ipc: host
    environment:
      HSA_OVERRIDE_GFX_VERSION: ${HSA_OVERRIDE_GFX_VERSION}
      HIP_VISIBLE_DEVICES: ${HIP_VISIBLE_DEVICES}
      OLLAMA_MODELS: /ollama-models
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_FLASH_ATTENTION: ${OLLAMA_FLASH_ATTENTION}
      OLLAMA_KV_CACHE_TYPE: ${OLLAMA_KV_CACHE_TYPE}
      OLLAMA_CONTEXT_LENGTH: ${OLLAMA_CONTEXT_LENGTH:-8192}
      OLLAMA_KEEP_ALIVE: ${OLLAMA_KEEP_ALIVE}
      OLLAMA_NUM_PARALLEL: ${OLLAMA_NUM_PARALLEL}
      OLLAMA_MAX_LOADED_MODELS: ${OLLAMA_MAX_LOADED_MODELS}
      OLLAMA_CHAT_MODEL: ${OLLAMA_CHAT_MODEL}
      OLLAMA_EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL}
    volumes:
      - ${OLLAMA_MODELS_DIR}:/ollama-models
      - ./ollama/entrypoint.sh:/entrypoint.sh:ro
    ports:
      - "11434:11434"
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 20
      start_period: 60s

  backend-inference:
    build:
      context: ./backend_inference
      dockerfile: Dockerfile
    container_name: rag-suite-backend-inference
    restart: unless-stopped
    environment:
      OLLAMA_URL: http://ollama:11434
      OLLAMA_TIMEOUT_SECONDS: ${OLLAMA_TIMEOUT_SECONDS:-300}
    depends_on:
      ollama:
        condition: service_healthy
    ports:
      - "${INFERENCE_BACKEND_PORT:-8010}:8010"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://127.0.0.1:8010/v1/health', timeout=3)",
        ]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s

  backend-ingestion:
    build:
      context: ./backend_ingestion
      dockerfile: Dockerfile
    container_name: rag-suite-backend-ingestion
    restart: unless-stopped
    environment:
      DATABASE_URL: sqlite:///./data/control_plane.db
      QDRANT_URL: http://qdrant:6333
      INFERENCE_API_URL: http://backend-inference:8010/v1
      INFERENCE_TIMEOUT_SECONDS: ${INFERENCE_TIMEOUT_SECONDS:-300}
      OLLAMA_CHAT_MODEL: ${OLLAMA_CHAT_MODEL}
      OLLAMA_EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL}
      QDRANT_COLLECTION_PREFIX: ${QDRANT_COLLECTION_PREFIX}
    volumes:
      - ${DATA_DIR}:/app/data
    depends_on:
      qdrant:
        condition: service_healthy
      backend-inference:
        condition: service_healthy
    ports:
      - "${INGESTION_BACKEND_PORT:-8000}:8000"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://127.0.0.1:8000/v1/health', timeout=3)",
        ]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s

  backend-rag:
    build:
      context: ./backend_rag
      dockerfile: Dockerfile
    container_name: rag-suite-backend-rag
    restart: unless-stopped
    environment:
      DATABASE_URL: sqlite:///./data/control_plane.db
      QDRANT_URL: http://qdrant:6333
      INFERENCE_API_URL: http://backend-inference:8010/v1
      INFERENCE_TIMEOUT_SECONDS: ${INFERENCE_TIMEOUT_SECONDS:-300}
      OLLAMA_CHAT_MODEL: ${OLLAMA_CHAT_MODEL}
      OLLAMA_EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL}
      RAG_CHECKPOINT_PATH: ${RAG_CHECKPOINT_PATH:-./data/rag_memory_checkpoints.db}
      RAG_SESSIONS_DATABASE_URL: ${RAG_SESSIONS_DATABASE_URL:-sqlite:///./data/rag_sessions.db}
    volumes:
      - ${DATA_DIR}:/app/data
    depends_on:
      qdrant:
        condition: service_healthy
      backend-inference:
        condition: service_healthy
    ports:
      - "${RAG_BACKEND_PORT:-8020}:8020"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://127.0.0.1:8020/v1/health', timeout=3)",
        ]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: rag-suite-frontend
    restart: unless-stopped
    environment:
      VITE_API_BASE_URL: http://backend-ingestion:8000/v1
      VITE_RAG_API_BASE_URL: http://backend-rag:8020/v1
      VITE_INFERENCE_API_BASE_URL: http://backend-inference:8010/v1
    depends_on:
      backend-ingestion:
        condition: service_healthy
      backend-inference:
        condition: service_healthy
      backend-rag:
        condition: service_healthy
    ports:
      - "5173:5173"

networks:
  default:
    name: rag-suite-network
